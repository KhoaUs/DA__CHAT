import streamlit as st
from streamlit_mic_recorder import mic_recorder
from modules.agent_engine import init_agent
from modules.visualization import DashboardRenderer
import os
from dotenv import load_dotenv
import speech_recognition as sr
import io
import json
import datetime
from langchain_core.messages import HumanMessage, ToolMessage

# --- 1. C·∫§U H√åNH TRANG & CSS ---
st.set_page_config(page_title="E-Commerce AI Analyst", page_icon="üõçÔ∏è", layout="wide", initial_sidebar_state="expanded")

# T·∫Øt log r√°c c·ªßa Google
os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GLOG_minloglevel"] = "2"

load_dotenv() 

# CSS T√πy ch·ªânh giao di·ªán
st.markdown("""
<style>
    /* ·∫®n menu m·∫∑c ƒë·ªãnh */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header[data-testid="stHeader"] {background-color: transparent;}
    
    /* Bong b√≥ng chat */
    .stChatMessage {padding: 1rem; border-radius: 15px; margin-bottom: 10px; border: 1px solid #f0f2f6;}
    .stChatMessage .st-emotion-cache-1p1m4ay {background-color: #ffffff; border: 1px solid #eee;}
    
    /* Ti√™u ƒë·ªÅ */
    .main-title {font-size: 2.5rem; font-weight: 700; color: #FF4B4B; text-align: center; margin-bottom: 0.5rem;}
    .sub-title {text-align: center; color: #666; font-size: 1.1rem; margin-bottom: 2rem;}
    
    /* N√∫t mic */
    .stButton button {height: 50px; border-radius: 50%; width: 50px;}
    
    /* Expander Dashboard */
    .streamlit-expanderHeader {font-weight: 600; color: #31333F; background-color: #f0f2f6; border-radius: 10px;}
</style>
""", unsafe_allow_html=True)

# --- 2. H√ÄM H·ªñ TR·ª¢ ---
def parse_ai_response(content):
    """L√†m s·∫°ch c√¢u tr·∫£ l·ªùi t·ª´ AI"""
    if isinstance(content, str): return content
    elif isinstance(content, list):
        text_parts = [item.get('text', '') for item in content if item.get('type') == 'text']
        return " ".join(text_parts)
    return str(content)

def transcribe_audio(audio_bytes):
    """Chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i th√†nh vƒÉn b·∫£n"""
    r = sr.Recognizer()
    try:
        audio_data = io.BytesIO(audio_bytes)
        with sr.AudioFile(audio_data) as source:
            audio = r.record(source)
            text = r.recognize_google(audio, language="vi-VN")
            return text
    except Exception:
        return None

def log_to_file(user_input, tool_logs, ai_response):
    """Ghi log ho·∫°t ƒë·ªông v√†o file JSONL"""
    log_entry = {
        "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "user_input": user_input,
        "tools_called": tool_logs,
        "ai_response": ai_response
    }
    with open("agent_activity.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

# --- 3. SIDEBAR ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/4712/4712035.png", width=80)
    st.title("Control Center")
    
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        st.error("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y GOOGLE_API_KEY")
        st.stop()
    
    st.markdown("### ü§ñ C·∫•u h√¨nh AI")
    # C·∫≠p nh·∫≠t danh s√°ch model chu·∫©n
    model_options = {
        "Gemini 2.5 Flash (Khuy√™n d√πng)": "gemini-2.5-flash",
        "Gemini 2.5 Pro (Th√¥ng minh nh·∫•t)": "gemini-2.5-pro",
        "Gemini 2.5 Flash Lite (Si√™u t·ªëc)": "gemini-2.5-flash-lite",
    }
    selected_model_label = st.selectbox("Ch·ªçn Model:", options=list(model_options.keys()), index=0)
    selected_model_name = model_options[selected_model_label]
    
    st.markdown("---")
    
    # N√∫t t·∫£i log
    st.markdown("### üìù Nh·∫≠t k√Ω")
    if os.path.exists("agent_activity.jsonl"):
        with open("agent_activity.jsonl", "r", encoding="utf-8") as f:
            st.download_button("üì• T·∫£i File Log (.jsonl)", f, "agent_activity.jsonl", "application/json")

# --- 4. GIAO DI·ªÜN CH√çNH ---
st.markdown('<div class="main-title">üõçÔ∏è E-Commerce Smart Analyst</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">Tr·ª£ l√Ω ph√¢n t√≠ch th·ªã tr∆∞·ªùng & ƒë·ªëi th·ªß c·∫°nh tranh b·∫±ng AI</div>', unsafe_allow_html=True)

# Kh·ªüi t·∫°o Session State
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ch√†o b·∫°n! H√¥m nay ch√∫ng ta s·∫Ω ph√¢n t√≠ch s·∫£n ph·∫©m n√†o?"}]
if "last_tool_output" not in st.session_state:
    st.session_state.last_tool_output = None
if "prev_audio_bytes" not in st.session_state:
    st.session_state.prev_audio_bytes = None

# Container ch·ª©a l·ªãch s·ª≠ chat
chat_container = st.container()

# Container nh·∫≠p li·ªáu (N·∫±m d∆∞·ªõi c√πng)
input_container = st.container()

with input_container:
    col1, col2 = st.columns([1, 15])
    with col1: # N√∫t Mic
        audio = mic_recorder(start_prompt="üéôÔ∏è", stop_prompt="‚èπÔ∏è", key='recorder', format="wav")
    with col2: # √î nh·∫≠p li·ªáu
        text_input = st.chat_input("V√≠ d·ª•: Ph√¢n t√≠ch th·ªã tr∆∞·ªùng tai nghe bluetooth...")

# --- 5. X·ª¨ L√ù INPUT ---
final_user_input = None
if audio and audio['bytes'] != st.session_state.prev_audio_bytes:
    st.session_state.prev_audio_bytes = audio['bytes']
    with st.spinner("üéß ƒêang nghe..."):
        text = transcribe_audio(audio['bytes'])
        if text: final_user_input = text
        else: st.toast("Kh√¥ng nghe r√µ gi·ªçng n√≥i.")
elif text_input:
    final_user_input = text_input

# --- 6. CORE LOGIC (AI AGENT) ---
if final_user_input:
    # 6.1. Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": final_user_input})
    st.session_state.last_tool_output = None # Reset Dashboard c≈©
    
    try:
        # Kh·ªüi t·∫°o Agent
        agent = init_agent(api_key, model_name=selected_model_name)
        
        with st.spinner(f"AI ƒëang ph√¢n t√≠ch d·ªØ li·ªáu..."):
            # G·ªçi Agent th·ª±c thi
            response_state = agent.invoke({"messages": [HumanMessage(content=final_user_input)]})
            returned_messages = response_state['messages']
            
            # 6.2. Tr√≠ch xu·∫•t Log (AI ƒë√£ g·ªçi tool g√¨?)
            tool_logs = []
            for msg in returned_messages:
                if hasattr(msg, 'tool_calls') and len(msg.tool_calls) > 0:
                    for tool_call in msg.tool_calls:
                        tool_logs.append({
                            "name": tool_call['name'],
                            "args": tool_call['args']
                        })
            
            # 6.3. L·∫•y c√¢u tr·∫£ l·ªùi text
            raw_content = returned_messages[-1].content
            ai_response = parse_ai_response(raw_content)
            
            # 6.4. Ghi log h·ªá th·ªëng
            log_to_file(final_user_input, tool_logs, ai_response)
            
            # 6.5. Hi·ªÉn th·ªã Log Tool ra m√†n h√¨nh (Debug UI)
            if tool_logs:
                with st.chat_message("ai"):
                    with st.expander("üõ†Ô∏è [DEBUG] AI Execution Log", expanded=False):
                        st.json(tool_logs)

            # 6.6. B·∫Øt d·ªØ li·ªáu Dashboard (L·∫•y output c·ªßa tool cu·ªëi c√πng)
            for msg in reversed(returned_messages):
                if isinstance(msg, ToolMessage):
                    st.session_state.last_tool_output = {
                        "tool": msg.name, 
                        "data": msg.content
                    }
                    break 
        
        # 6.7. L∆∞u c√¢u tr·∫£ l·ªùi AI
        st.session_state.messages.append({"role": "assistant", "content": ai_response})

    except Exception as e:
        st.error(f"L·ªói h·ªá th·ªëng: {e}")

# --- 7. RENDER CHAT HISTORY ---
with chat_container:
    for msg in st.session_state.messages:
        avatar = "ü§ñ" if msg["role"] == "assistant" else "üë§"
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

# --- 8. RENDER DASHBOARD (CH√åA KH√ìA C·ª¶A ·ª®NG D·ª§NG) ---
if st.session_state.last_tool_output:
    st.markdown("---")
    
    tool_type = st.session_state.last_tool_output['tool']
    data_content = st.session_state.last_tool_output['data']
    
    # Container Dashboard x·ªãn s√≤
    with st.expander("üìä DASHBOARD PH√ÇN T√çCH CHI TI·∫æT", expanded=True):
        try:
            # === Mapping Tool -> Visualization Function ===
            
            # 1. C√°c Dashboard c∆° b·∫£n
            if tool_type == "get_price_stats":
                DashboardRenderer.render_price_dashboard(data_content)
                
            elif tool_type == "get_sales_stats":
                DashboardRenderer.render_sales_dashboard(data_content)
                
            elif tool_type == "get_review_stats":
                DashboardRenderer.render_review_dashboard(data_content)
            
            # 2. Dashboard T·ªïng h·ª£p & N√¢ng cao
            elif tool_type == "get_product_analysis":
                DashboardRenderer.render_combined_dashboard(data_content)
            
            elif tool_type == "get_advanced_market_analysis":
                DashboardRenderer.render_advanced_dashboard(data_content)
            
            # 3. Dashboard Top Brand (ƒê√£ s·ª≠a l·ªói logic c≈©)
            elif tool_type == "get_top_brands_analysis":
                # Truy·ªÅn tr·ª±c ti·∫øp data_content (chu·ªói JSON), 
                # DashboardRenderer s·∫Ω t·ª± parse ƒë·ªÉ l·∫•y ƒë·ªß rank_by, share_metric
                DashboardRenderer.render_top_brands(data_content)
                
            # 4. Dashboard Category Trends (M·ªõi th√™m)
            elif tool_type == "get_category_trends":
                DashboardRenderer.render_category_trends(data_content)
                
        except Exception as e:
            st.error(f"‚ö†Ô∏è Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì: {e}")
            with st.expander("Xem d·ªØ li·ªáu th√¥ (Raw Data)"):
                st.write(data_content)